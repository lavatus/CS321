{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABSA_Hotel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZBhST3xqrymV-A_0NRtmb43VhIY4oCj-",
      "authorship_tag": "ABX9TyM576/3sPX0a84jysidq7Q3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavatus/CS321/blob/main/ABSA_Hotel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhh1VtDviF0J",
        "outputId": "afaa9d06-af74-43d3-eb8f-0e353b1c7282"
      },
      "source": [
        "!git clone -q https://github.com/DNThuan/AspectBasedSentimentAnalysis.git\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "AspectBasedSentimentAnalysis  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO6AGIoIb_Hh"
      },
      "source": [
        "# 1) Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FdGy4VyiYPe"
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tknJtJPTYYr"
      },
      "source": [
        "def read_data(path):\n",
        "  with open(path) as f:\n",
        "    data = f.read().split(\"\\n\\n\")\n",
        "  f.close()\n",
        "  for i in range(len(data)):\n",
        "    temp=data[i].split(\"\\n\")\n",
        "    data[i]=temp[1:3]\n",
        "  return data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1omtbZ7TZan",
        "outputId": "75c71783-71c9-4387-9a20-4949dbcaf88e"
      },
      "source": [
        "path_train = \"/content/AspectBasedSentimentAnalysis/VLSP2018_SA_Hotel/1-VLSP2018-SA-Hotel-train (7-3-2018).txt\"\n",
        "path_dev =  \"/content/AspectBasedSentimentAnalysis/VLSP2018_SA_Hotel/2-VLSP2018-SA-Hotel-dev (7-3-2018).txt\"\n",
        "path_test = \"/content/AspectBasedSentimentAnalysis/VLSP2018_SA_Hotel/3-VLSP2018-SA-Hotel-test (8-3-2018).txt\"\n",
        "\n",
        "train = np.array(read_data(path_train))\n",
        "dev = np.array(read_data(path_dev))\n",
        "test = np.array(read_data(path_test))\n",
        "\n",
        "print(\"Train: \",train.shape)\n",
        "print(\"Dev: \",dev.shape)\n",
        "print(\"Test: \",test.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (3000, 2)\n",
            "Dev:  (2000, 2)\n",
            "Test:  (600, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoygYsSrcDnl"
      },
      "source": [
        "#2) Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKm0ffl9j11w"
      },
      "source": [
        "## 2.1 Review data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9tCv_allrO9"
      },
      "source": [
        "### 2.1.1 Delete emoji"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m85xFJgmkg1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990adade-1a95-432f-be35-0a398803e7c4"
      },
      "source": [
        "!pip install -q emoji\n",
        "import emoji\n",
        "from sklearn.preprocessing import  FunctionTransformer\n",
        "\n",
        "def Delete_emoji(texts):\n",
        "    return np.array([emoji.get_emoji_regexp().sub('', text) for text in texts])\n",
        "\n",
        "delete_emoji = FunctionTransformer(Delete_emoji)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 30.1 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvN1ij13muYn"
      },
      "source": [
        "### 2.1.2 Replace value of money by special character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmGl47x8mttE"
      },
      "source": [
        "import re\n",
        "\n",
        "def Replace_Symbol(texts):\n",
        "  texts_result = []\n",
        "  for text in texts:\n",
        "    distance_pattern = \"([0-9.,]{1,9}?.km)|([0-9.,]{1,9}?.cây số)|([0-9.,]{1,9}?.cây)|([0-9.,]{1,9}?.mét)|([0-9.,]{1,3}?.m)\"\n",
        "    text_result = re.sub(distance_pattern, 'khoang_cach', text)\n",
        "    money_pattern = \"(\\d{1,3}k.{0})|([0-9.]{1,9}?.vnd)|([0-9.]{1,9}?.việt nam đồng)|([0-9.]{1,9}?.đồng)\"\n",
        "    text_result = re.sub(money_pattern, 'gia_tien', text_result)\n",
        "    texts_result.append(text_result)\n",
        "  return texts_result\n",
        "replace_symbol = FunctionTransformer(Replace_Symbol)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41DN85JiphwB"
      },
      "source": [
        "### 2.1.3 Delete special character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HzCKKYIpr4E"
      },
      "source": [
        "def Delete_Special_Character(texts):\n",
        "  texts_result = []\n",
        "  for text in texts:\n",
        "    special_character_pattern = \"[+=<>@#$%^&~]\"\n",
        "    text_result = re.sub(special_character_pattern, '', text)\n",
        "    words = text_result.split()\n",
        "    text_result = ' '.join(words)\n",
        "    texts_result.append(text_result)\n",
        "  return texts_result\n",
        "delete_special_character = FunctionTransformer(Delete_Special_Character)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yUljmyDqwC1"
      },
      "source": [
        "### 2.1.4 Normalize elongate words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GuY4xhrqxG7"
      },
      "source": [
        "def Normalize_Elongate_Words(texts):\n",
        "  texts_result = []\n",
        "  for text in texts:\n",
        "    elongate_pattern = r\"(\\w)\\1*\"\n",
        "    text_result = re.sub(elongate_pattern, r'\\1', text)\n",
        "    texts_result.append(text_result)\n",
        "  return texts_result\n",
        "normalize_elongate_words = FunctionTransformer(Normalize_Elongate_Words)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxltn5RxrqOG"
      },
      "source": [
        "### 2.1.5 Replace negative words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNvzfzCarBLy"
      },
      "source": [
        "\n",
        "def Replace_Negative_Words(texts):\n",
        "  texts_result = []\n",
        "  for text in texts:\n",
        "\n",
        "    hotel_pattern = r\"\\bksạn\\b|\\bk sạn\\b|\\bks\\b|\\bKS\\b|\\bKs\\b\"\n",
        "    new = re.sub(hotel_pattern, 'khách sạn', text)\n",
        "    new = re.sub(r\"\\bnc\\b\", 'nước', new)\n",
        "    new = re.sub(r\"\\bnvs\\b|\\bnhà vs\\b\", 'nhà vệ sinh', new)\n",
        "    new = re.sub(r\"\\bnv\\b\", 'nhân viên', new)\n",
        "    new = re.sub(r\"\\bvs\\b\", 'vệ sinh', new)\n",
        "    \n",
        "    negative_pattern = r\"\\bkh\\b|\\bko\\b|\\bkhg\\b|\\bkhong\\b|\\bk\\b|\\bhông\\b|\\bhem\\b|\\bk0\\b\"\n",
        "    new = re.sub(negative_pattern, 'không', new)\n",
        "    new = re.sub(r\"\\bdc\\b|\\bdk\\b\", 'được', new)\n",
        "\n",
        "    new = re.sub(r\" 1 \", \" một \", new)\n",
        "\n",
        "    texts_result.append(new)\n",
        "  return texts_result\n",
        "replace_negative_words = FunctionTransformer(Replace_Negative_Words)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8gYljq2LceO"
      },
      "source": [
        "### 2.1.6 Pos tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACYqYn03NblJ",
        "outputId": "16a0625e-8cd6-434e-9e12-b8db0951973a"
      },
      "source": [
        "!pip install pyvi\n",
        "from pyvi import ViTokenizer"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (1.0.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.62.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhQGxCgDAq4y"
      },
      "source": [
        "def Pos_Tagging(texts):\n",
        "  result = []\n",
        "  for text in texts:\n",
        "    postag =  ViPosTagger.postagging(ViTokenizer.tokenize(text))\n",
        "    list_drop = [\"F\",\"E\",\"P\",\"L\",\"T\"]\n",
        "    new_result = \"\"\n",
        "    for index, catalog in enumerate(postag[1]):\n",
        "      if catalog not in list_drop:\n",
        "        new_result +=postag[0][index] + \" \"\n",
        "    result.append(new_result)\n",
        "  return result\n",
        "pos_tagging = FunctionTransformer(Pos_Tagging)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShEHUVV6sxrm"
      },
      "source": [
        "## 2.2 Tag data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL7UZhs6s2n3"
      },
      "source": [
        "### 2.2.1 Label separation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYaU70BJs6bw"
      },
      "source": [
        "# Tìm vị trí các cặp dấu ngoặc\n",
        "# Input: một nhãn dạng string\n",
        "def find_start_end(label):\n",
        "  start = 0\n",
        "  end = 0\n",
        "  lst_start=[]\n",
        "  lst_end=[]\n",
        "  for index ,char in enumerate(label):\n",
        "    if char == \"{\":\n",
        "      start = index\n",
        "      lst_start.append(start)\n",
        "    elif char == \"}\":\n",
        "      end = index\n",
        "      lst_end.append(end)\n",
        "  return tuple(zip(lst_start,lst_end))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9ATiZJ2iLW-"
      },
      "source": [
        "def Label_to_ListDict(labels):\n",
        "  list_dict_label = list()\n",
        "  for label in labels:\n",
        "    lst = []\n",
        "    index = tuple(find_start_end(label))\n",
        "    for i in index:\n",
        "      dict_label = dict()\n",
        "      aspect, polarity = label[i[0]+1:i[1]].replace(\" \",\"\").split(\",\")\n",
        "      dict_label[aspect] = polarity\n",
        "      lst.append(dict_label)\n",
        "    list_dict_label.append(lst)\n",
        "  return list_dict_label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik5kCzY1LFCu"
      },
      "source": [
        "def Label_str_to_list(label):\n",
        "  index = tuple(find_start_end(label))\n",
        "  aspect_temp=[]\n",
        "  polarity_temp=[]\n",
        "  for i in index:\n",
        "    temp = label[i[0]+1:i[1]].replace(\" \",\"\").split(\",\")\n",
        "    aspect_temp.append(temp[0])\n",
        "    polarity_temp.append(temp[1])\n",
        "  return aspect_temp, polarity_temp"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbAbh3W4JVKP"
      },
      "source": [
        "def separate_label(labels):\n",
        "  aspect= []\n",
        "  polarity = []\n",
        "  SA = []\n",
        "  for label in labels:\n",
        "    temp = Label_str_to_list(label)\n",
        "    aspect.append(temp[0])\n",
        "    polarity.append(temp[1])\n",
        "\n",
        "    sa_temp= []\n",
        "    for i in range(len(temp[0])):\n",
        "      sa = \"{\"+temp[0][i]+\", \"+temp[1][i]+\"}\"\n",
        "      sa_temp.append(sa)\n",
        "    SA.append(sa_temp)\n",
        "\n",
        "  return np.array(aspect, dtype=object), np.array(polarity, dtype=object), np.array(SA, dtype=object)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8YvF51t6z5T"
      },
      "source": [
        "### 2.2.2 Binary Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO5FGIhIHECy"
      },
      "source": [
        "# Load list label\n",
        "\n",
        "def read_label(path):\n",
        "  with open(path) as f:\n",
        "    data = json.load(f)\n",
        "  f.close()\n",
        "  return data\n",
        "\n",
        "aspect_path = \"/content/AspectBasedSentimentAnalysis/Label/aspect.json\"\n",
        "SA_path = \"/content/AspectBasedSentimentAnalysis/Label/SA.json\"\n",
        "aspect_labels = read_label(aspect_path)\n",
        "AS_labels = read_label(SA_path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTMDQnX3YakY",
        "outputId": "87b29f4e-f31e-40e2-8393-82d545b06019"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "transform_label= MultiLabelBinarizer().fit([aspect_labels])\n",
        "list_label = transform_label.classes_\n",
        "print(list_label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['FACILITIES#CLEANLINESS' 'FACILITIES#COMFORT'\n",
            " 'FACILITIES#DESIGN&FEATURES' 'FACILITIES#GENERAL'\n",
            " 'FACILITIES#MISCELLANEOUS' 'FACILITIES#PRICES' 'FACILITIES#QUALITY'\n",
            " 'FOOD&DRINKS#MISCELLANEOUS' 'FOOD&DRINKS#PRICES' 'FOOD&DRINKS#QUALITY'\n",
            " 'FOOD&DRINKS#STYLE&OPTIONS' 'HOTEL#CLEANLINESS' 'HOTEL#COMFORT'\n",
            " 'HOTEL#DESIGN&FEATURES' 'HOTEL#GENERAL' 'HOTEL#MISCELLANEOUS'\n",
            " 'HOTEL#PRICES' 'HOTEL#QUALITY' 'LOCATION#GENERAL' 'ROOMS#CLEANLINESS'\n",
            " 'ROOMS#COMFORT' 'ROOMS#DESIGN&FEATURES' 'ROOMS#GENERAL'\n",
            " 'ROOMS#MISCELLANEOUS' 'ROOMS#PRICES' 'ROOMS#QUALITY'\n",
            " 'ROOM_AMENITIES#CLEANLINESS' 'ROOM_AMENITIES#COMFORT'\n",
            " 'ROOM_AMENITIES#DESIGN&FEATURES' 'ROOM_AMENITIES#GENERAL'\n",
            " 'ROOM_AMENITIES#MISCELLANEOUS' 'ROOM_AMENITIES#PRICES'\n",
            " 'ROOM_AMENITIES#QUALITY' 'SERVICE#GENERAL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pluBIDvrXmwr"
      },
      "source": [
        "## 2.3 Make dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-M_oO_5HsY3"
      },
      "source": [
        "\n",
        "def data_Frame(label_y):\n",
        "  aspect, polarity,_ =  separate_label(label_y)\n",
        "  dic = Label_to_ListDict(label_y)\n",
        "  aspect_tf = transform_label.transform(aspect)\n",
        "\n",
        "  for index1,label in enumerate(aspect_tf):\n",
        "    count = 0\n",
        "    for index2,a in enumerate(label):\n",
        "      if a == 1:\n",
        "        if polarity[index1][count] == \"positive\":\n",
        "          aspect_tf[index1][index2] = 10\n",
        "         \n",
        "        elif polarity[index1][count] == \"negative\":\n",
        "          aspect_tf[index1][index2] = 20\n",
        "    \n",
        "        else:\n",
        "          aspect_tf[index1][index2] = 30\n",
        "        count+=1\n",
        "\n",
        "  return aspect_tf"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI4aVv59WRho"
      },
      "source": [
        "def make_data_frame(texts,labels,list_label):\n",
        "  data = {\"Review\":texts}\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  label = data_Frame(labels)\n",
        "  for i in range(len(aspect_labels)):\n",
        "    new_col = label[:,i]\n",
        "    df[transform_label.classes_[i]] = new_col.tolist()\n",
        "  return df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3_0psLbXyYH"
      },
      "source": [
        "### 2.3.1 Aspect dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goC8td1nxvFF"
      },
      "source": [
        "def get_aspect_data_frame(df,list_label):\n",
        "    df_ =df.copy()\n",
        "    for aspect in aspect_labels:\n",
        "        df_[aspect]=df_[aspect].replace(10,1)\n",
        "        df_[aspect]=df_[aspect].replace(20,1)\n",
        "        df_[aspect]=df_[aspect].replace(30,1)\n",
        "    df_ = df_.fillna(0)\n",
        "    return df_"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz9sb5SOX4tP"
      },
      "source": [
        "### 2.3.2 Positive dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yX6uXBn6xlB"
      },
      "source": [
        "def get_positive_data_frame(df,list_label):\n",
        "    df_ =df.copy()\n",
        "    for aspect in aspect_labels:\n",
        "        df_[aspect]=df_[aspect].replace(10,1)\n",
        "        df_[aspect]=df_[aspect].replace(20,0)\n",
        "        df_[aspect]=df_[aspect].replace(30,0)\n",
        "    df_ = df_.fillna(0)\n",
        "    return df_"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiYy2eYQX4Gu"
      },
      "source": [
        "### 2.3.3 Negative dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoFGVqU-6xnB"
      },
      "source": [
        "def get_negative_data_frame(df,list_label):\n",
        "    df_ =df.copy()\n",
        "    for aspect in aspect_labels:\n",
        "        df_[aspect]=df_[aspect].replace(10,0)\n",
        "        df_[aspect]=df_[aspect].replace(20,1)\n",
        "        df_[aspect]=df_[aspect].replace(30,0)\n",
        "    df_ = df_.fillna(0)\n",
        "    return df_"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glPtzxf4X_0S"
      },
      "source": [
        "### 2.3.4 Neutral dataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Sy7uy162Ha"
      },
      "source": [
        "def get_neutral_data_frame(df,list_label):\n",
        "    df_ =df.copy()\n",
        "    for aspect in aspect_labels:\n",
        "        df_[aspect]=df_[aspect].replace(10,0)\n",
        "        df_[aspect]=df_[aspect].replace(20,0)\n",
        "        df_[aspect]=df_[aspect].replace(30,1)\n",
        "    df_ = df_.fillna(0)\n",
        "    return df_"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YXfZoru5yD4"
      },
      "source": [
        "# 3) Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3-g3AyHY0nR"
      },
      "source": [
        "## 3.1 Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvkjQtzoX3QX"
      },
      "source": [
        "X_train, y_train = train[:,0], train[:,1]\n",
        "X_dev,   y_dev   = dev[:,0],   dev[:,1]\n",
        "X_test,  y_test  = test[:,0],  test[:,1]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ik68Om9sF5"
      },
      "source": [
        "def getdata(df,list_label,kind):\n",
        "  if kind == \"aspect\":\n",
        "    data = get_aspect_data_frame(df,list_label)\n",
        "  elif kind == \"positive\":\n",
        "    data= get_positive_data_frame(df,list_label)\n",
        "  elif kind ==\"negative\":\n",
        "    data = get_negative_data_frame(df,list_label)\n",
        "  elif kind ==\"neutral\":\n",
        "    data = get_neutral_data_frame(df,list_label)  \n",
        "\n",
        "  X = data.Review\n",
        "  y = data.drop(\"Review\",1)\n",
        "  return X,y"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh5Xen2vFn1B"
      },
      "source": [
        "def prepare_data(X,y,list_label):\n",
        "  data = make_data_frame(X,y,list_label)\n",
        "\n",
        "  X_aspect, y_aspect = getdata(data, list_label, \"aspect\")\n",
        "  X_positive, y_positive = getdata(data, list_label, \"positive\")\n",
        "  X_negative, y_negative = getdata(data, list_label, \"negative\")\n",
        "  X_neutral, y_neutral = getdata(data, list_label, \"neutral\")\n",
        "\n",
        "  X_aspect_tf = preproceesing_data.transform(X_aspect).toarray()\n",
        "  X_positive_tf = preproceesing_data.transform(X_positive).toarray()\n",
        "  X_negative_tf = preproceesing_data.transform(X_negative).toarray()\n",
        "  X_neutral_tf = preproceesing_data.transform(X_neutral).toarray()\n",
        "  dic = {\n",
        "      \"X_aspect_tf\":X_aspect_tf,\n",
        "      \"X_positive_tf\":X_positive_tf,\n",
        "      \"X_negative_tf\":X_negative_tf,\n",
        "      \"X_neutral_tf\":X_neutral_tf,\n",
        "      \"y_aspect\":y_aspect,\n",
        "      \"y_positive\":y_positive,\n",
        "      \"y_negative\":y_negative,\n",
        "      \"y_neutral\":y_neutral\n",
        "  }\n",
        "\n",
        "  return dic"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vddmDRTmZJlT"
      },
      "source": [
        "## 3.2 Binary label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmVXpvCG9TFj"
      },
      "source": [
        "transform_label_SA= MultiLabelBinarizer().fit([AS_labels])\n",
        "#print(transform_label_SA.classes_)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY1hxLnr3aJK"
      },
      "source": [
        "def show_label(pred_as, pred_pos, pred_neg, pred_neu):\n",
        "  labels = []\n",
        "  for index, value in enumerate(pred_as):\n",
        "    if value == 1:\n",
        "      label = \"{\"\n",
        "      if pred_pos[index] ==1:\n",
        "        label += str(list_label[index])+\", \"+\"positive\"\n",
        "      elif pred_neg[index] ==1:\n",
        "        label += str(list_label[index])+\", \"+\"negative\"\n",
        "      elif pred_neu[index] ==1:\n",
        "        label += str(list_label[index])+\", \"+\"neutral\"\n",
        "      label+=\"}\"\n",
        "      labels.append(label)\n",
        "  return labels"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dHrqp0LYIK4"
      },
      "source": [
        "## 3.3 Make Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9A_Z70517W6"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "preproceesing_data = make_pipeline(delete_emoji,\n",
        "                              replace_symbol,\n",
        "                              delete_special_character,\n",
        "                              normalize_elongate_words,\n",
        "                              replace_negative_words,\n",
        "                              pos_tagging,\n",
        "                              TfidfVectorizer(sublinear_tf=True, min_df=5, ngram_range=(1,2), stop_words='english')).fit(X_train)\n",
        "                              \n"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuatJNo4TTL"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def score(y_true, y_pred):\n",
        "  print(\"Precison: \",metrics.precision_score(y_true, y_pred, average='micro'))\n",
        "  print(\"Recall: \",metrics.recall_score(y_true, y_pred, average='micro'))\n",
        "  print(\"F1: \",metrics.f1_score(y_true, y_pred, average='micro'))\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ3gy6hSaRC_"
      },
      "source": [
        "## 3.4 Get data training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhaV09KqG3TD"
      },
      "source": [
        "data_train = prepare_data(X_train,y_train,list_label)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT03H5STHG0k"
      },
      "source": [
        "data_dev = prepare_data(X_dev,y_dev,list_label)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xp_QYJIta07"
      },
      "source": [
        "data_test = prepare_data(X_test,y_test,list_label)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFWPJcIJZT1v"
      },
      "source": [
        "## 3.5 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPz4DKWT5lUc"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "clf_aspect = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
        "clf_positive = OneVsRestClassifier(LinearSVC(), n_jobs=1)         \n",
        "clf_negative = OneVsRestClassifier(LinearSVC(), n_jobs=1)\n",
        "clf_neutral = OneVsRestClassifier(LinearSVC(), n_jobs=1)   \n",
        "          "
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQxKAY9rCf85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40c0a9a-0bb5-4c17-dd7b-3ac8eb73f4dc"
      },
      "source": [
        "clf_aspect.fit(data_train[\"X_aspect_tf\"], data_train[\"y_aspect\"])\n",
        "clf_positive.fit(data_train[\"X_positive_tf\"], data_train[\"y_positive\"])\n",
        "clf_negative.fit(data_train[\"X_negative_tf\"], data_train[\"y_negative\"])\n",
        "clf_neutral.fit(data_train[\"X_neutral_tf\"], data_train[\"y_neutral\"])\n"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 31 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 31 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 31 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 23 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 27 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 30 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:80: UserWarning: Label not 31 is present in all training examples.\n",
            "  \"Label %s is present in all training examples.\" % str(classes[c])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LinearSVC(), n_jobs=1)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARWQamKW00vl"
      },
      "source": [
        "predict_aspect =  clf_aspect.predict(data_dev[\"X_aspect_tf\"])\n",
        "predict_positive = clf_positive.predict(data_dev[\"X_positive_tf\"])\n",
        "predict_negative = clf_negative.predict(data_dev[\"X_negative_tf\"])\n",
        "predict_neutral = clf_neutral.predict(data_dev[\"X_neutral_tf\"])"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwOXRv-C1WrC",
        "outputId": "bdeaa2db-2c96-4cfa-af6a-d2f9127222e7"
      },
      "source": [
        "score(data_dev[\"y_aspect\"],predict_aspect)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precison:  0.8041918429003021\n",
            "Recall:  0.5989312333005203\n",
            "F1:  0.6865479164987507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAOZwlxr7d2y"
      },
      "source": [
        "def model(X):\n",
        "  predict_aspect =  clf_aspect.predict(X)\n",
        "  predict_positive = clf_positive.predict(X)\n",
        "  predict_negative = clf_negative.predict(X)\n",
        "  predict_neutral = clf_neutral.predict(X)\n",
        "  \n",
        "  pred =[]\n",
        "  for i in range(len(X)):\n",
        "    rs = show_label(predict_aspect[i],predict_aspect[i],predict_negative[i],predict_neutral[i])\n",
        "    pred.append(rs)\n",
        "  return np.array(pred, dtype=object)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oE19IDVwixO"
      },
      "source": [
        "## 3.6 Predict in dev-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyIlIkceArOM"
      },
      "source": [
        "_,_, y_true = separate_label(y_dev)\n",
        "pre =  model(data_dev[\"X_aspect_tf\"])\n",
        "y_true_tf = transform_label_SA.transform(y_true)\n",
        "pre_tf = transform_label_SA.transform(pre)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru6Xo4TPA55_",
        "outputId": "8c242ced-799e-49cd-8914-4d3a53ca6e36"
      },
      "source": [
        "score(y_true_tf,pre_tf)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precison:  0.6306646525679759\n",
            "Recall:  0.4696948389818591\n",
            "F1:  0.5384057386958975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOovM3mowpz0"
      },
      "source": [
        "## 3.7 Predict in test-dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmir75uEwvYA"
      },
      "source": [
        "_,_, y_true = separate_label(y_test)\n",
        "pre =  model(data_test[\"X_aspect_tf\"])\n",
        "y_true_tf = transform_label_SA.transform(y_true)\n",
        "pre_tf = transform_label_SA.transform(pre)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpVMt85dw4xh",
        "outputId": "a9761490-b0f0-4170-bd54-a9d5d48145d7"
      },
      "source": [
        "score(y_true_tf,pre_tf)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precison:  0.6169334021683015\n",
            "Recall:  0.46246130030959753\n",
            "F1:  0.528644105286441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaL71EILZuvw"
      },
      "source": [
        "## 4) predict with txt file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_T04lejQ8Bx"
      },
      "source": [
        "path_file = \"/content/test.txt\"\n",
        "texts = read_data(path_file)\n",
        "texts = [x[0] for x in texts]\n",
        "text_tf = preproceesing_data.transform(texts).toarray()"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPtVYLDbu6nM"
      },
      "source": [
        "predicts = model(text_tf)\n",
        "file = open(\"file_predict.txt\",\"w\")\n",
        "with file as f:\n",
        "  for index,predict in enumerate(predicts):\n",
        "    f.write(\"#\"+str(index+1)+\"\\n\")\n",
        "    f.write(texts[index]+\"\\n\")\n",
        "    for i in predict:\n",
        "      f.write(i+\", \")\n",
        "    f.write(\"\\n\")\n",
        "    \n",
        "   \n",
        "f.close()"
      ],
      "execution_count": 226,
      "outputs": []
    }
  ]
}